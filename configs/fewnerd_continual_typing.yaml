dataset:
  type: 'continual'
  method_type: linear
  entity_blank_ratio: 0.0
  total_parts: p10
  special_part: p1
  extra_special_part: ''
  use_selected: False
  use_mask: True
  batch_new_old_ratio: 1  # per batch #new_sample_num / #old_sample_num
  batch_limit: 2500  # 20% is for validation
  dataset_name: 'fewnerd'
  batch_limit_policy: 2  # 0: not use batch_limit, 1: batch_limit*special_part_id, 2: batch_limit, 3: batch_limit + weight
  replay_frequency: 1
  seed: 100

dataloader:
    max_seq_length: 256

plm:
  model_name: llama
  model_path: decapoda-research/llama-7b-hf
  apply_lora: true
  lora_r: 4
  apply_adapter: false
  adapter_size: 64
  adapter_type: houlsby
  optimize:
    freeze_para: False
    lr: 0.0005
    weight_decay: 0.01
    adam_eps: 0.0001
    beta1: 0.9
    beta2: 0.999
#    scheduler:
#      warmup_ratio: 0.1

logging:
  path_base: checkpoints
  cycle_suffix: llama_bat2lib2500_t1
  unique_string: fewnerd_supervised_li_fine_p10_large_lora4_mk00_p1_llama_bat2lib2500_t1
  overwrite: true

task: fewshot
train:
  num_epochs: 10
  fewshot_epoch: 1
  cold_startup: false  # do extra training on the model
  verbalizer_strategy: mean
  batch_size: 8
  num_steps: -1
  save_step: -1
  save_option: 1  # 2 - every, 1 - best, 0 - none
  shuffle_data: True
  save_pretrained: False
  gradient_accumulation_steps: 1
  reduction_batch_size: 128
  train_target_pos: 1
  inference_target_pos: 1
  negative_weight: 0.5
  past_weight: 1.0
  similarity: dot
  continual_method: 'our'  # emr_abl for ablation study without progressive PETs
  null_expert_logit: -100
  use_expert_selector: false  # for split >= p2 when train_expert_selector == 2
  train_expert_selector: 0  # for split >= p2, 0-none, 1-co-train, 2-selector-then-expert
  teacher_forcing: true
  expert_selector_factor: 0.1
  expert_topk: 1
  ewc_lambda: 1.0
  loss_scale: 1.0
  loss_adverse_step: -1  # update loss adversarial weight every n steps
  valid_zero_shot: True

valid:
  fewshot_valid_ratio: 0.2
  batch_size: 32
  shuffle_data: False

test:
  fewshot_valid_ratio: 0.2
  batch_size: 32
  shuffle_data: False


device: cuda:0

reproduce:
  seed: 100
